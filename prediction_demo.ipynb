{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNx/SF5T9mu30A7f37ClkFL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashen-pabasara/fabric-defect-detection/blob/main/prediction_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup"
      ],
      "metadata": {
        "id": "XwpRfDAAAjB2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install ultralytics\n",
        "!pip install -q ultralytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sG2jpS7tOiC_",
        "outputId": "33877594-d530-4645-e042-272456b203b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PeZhVHre_gjO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b32b5d7-1f82-4589-c0bf-df040f23632d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import cv2\n",
        "import glob\n",
        "from ultralytics import YOLO\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Project Paths"
      ],
      "metadata": {
        "id": "tAZGHRVZAmAT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Path\n",
        "MODEL_PATH = \"/content/drive/My Drive/EEY9536 Data Science Project/Dataset/YOLO_Results/yolov8n_colab_run_b64/weights/best.pt\"\n",
        "\n",
        "# Dataset ZIP Path\n",
        "ZIP_PATH = \"/content/drive/My Drive/EEY9536 Data Science Project/Dataset/fabric_dataset.zip\"\n",
        "\n",
        "UNZIP_DESTINATION = \"/content/fabric_dataset\"\n",
        "SAMPLE_IMAGE_DIR = os.path.join(UNZIP_DESTINATION, \"images\", \"val\")\n",
        "OUTPUT_SLIDESHOW_PATH = \"/content/demo_slideshow.mp4\"\n",
        "LOCAL_RESULTS_DIR = \"/content/prediction_results\"\n",
        "\n",
        "# Final Output Path\n",
        "DRIVE_OUTPUT_DIR = \"/content/drive/My Drive/EEY9536 Data Science Project/Dataset/Demo_Video/\"\n",
        "FINAL_VIDEO_NAME = \"fabric_demo_with_boxes.mp4\"\n",
        "\n",
        "os.makedirs(DRIVE_OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"Model Path: {MODEL_PATH}\")\n",
        "print(f\"Dataset ZIP: {ZIP_PATH}\")\n",
        "print(f\"Final video will be saved to: {DRIVE_OUTPUT_DIR}\")"
      ],
      "metadata": {
        "id": "ofYrPqITAnfz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5133f09f-b585-42ae-b107-6eb31a9aaeef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Path: /content/drive/My Drive/EEY9536 Data Science Project/Dataset/YOLO_Results/yolov8n_colab_run_b64/weights/best.pt\n",
            "Dataset ZIP: /content/drive/My Drive/EEY9536 Data Science Project/Dataset/fabric_dataset.zip\n",
            "Final video will be saved to: /content/drive/My Drive/EEY9536 Data Science Project/Dataset/Demo_Video/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unzip Dataset"
      ],
      "metadata": {
        "id": "vUlrBHUXAqY2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Starting to unzip {ZIP_PATH} to /content/...\")\n",
        "!unzip -q -n \"{ZIP_PATH}\" -d \"/content/\"\n",
        "print(\"Dataset unzipped successfully.\")"
      ],
      "metadata": {
        "id": "tcxOR1UqArkw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8064a4e7-6661-401f-b76d-c3a413f5d9a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting to unzip /content/drive/My Drive/EEY9536 Data Science Project/Dataset/fabric_dataset.zip to /content/...\n",
            "Dataset unzipped successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Slideshow Video"
      ],
      "metadata": {
        "id": "SzQmR1U2At9R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "print(\"--- Part 1: Creating 'Slideshow' Video from DEFECTS ---\")\n",
        "\n",
        "labels_val_dir = os.path.join(UNZIP_DESTINATION, \"labels\", \"val\")\n",
        "images_val_dir = os.path.join(UNZIP_DESTINATION, \"images\", \"val\")\n",
        "NUM_IMAGES = 20\n",
        "\n",
        "# Find all defective images\n",
        "defective_image_files = []\n",
        "all_label_files = os.listdir(labels_val_dir)\n",
        "\n",
        "print(f\"Scanning {len(all_label_files)} labels in {labels_val_dir}...\")\n",
        "\n",
        "for label_file in all_label_files:\n",
        "    label_path = os.path.join(labels_val_dir, label_file)\n",
        "\n",
        "    # Check if the label file is NOT empty\n",
        "    if os.path.getsize(label_path) > 0:\n",
        "        # Find its matching image\n",
        "        image_name = label_file.replace('.txt', '.jpg')\n",
        "        image_path = os.path.join(images_val_dir, image_name)\n",
        "\n",
        "        if os.path.exists(image_path):\n",
        "            defective_image_files.append(image_path)\n",
        "\n",
        "print(f\"Found {len(defective_image_files)} defective images in the validation set.\")\n",
        "\n",
        "# Select 20 random samples\n",
        "if len(defective_image_files) < NUM_IMAGES:\n",
        "    print(f\"Warning: Found fewer than 20 defect images. Using all {len(defective_image_files)}.\")\n",
        "    sample_images = defective_image_files\n",
        "else:\n",
        "    sample_images = random.sample(defective_image_files, NUM_IMAGES)\n",
        "\n",
        "# Create the video\n",
        "frame = cv2.imread(sample_images[0])\n",
        "height, width, layers = frame.shape\n",
        "size = (width, height)\n",
        "\n",
        "# Define the video writer (1.0 FPS)\n",
        "out = cv2.VideoWriter(OUTPUT_SLIDESHOW_PATH,\n",
        "                      cv2.VideoWriter_fourcc(*'MP4V'),\n",
        "                      1.0,\n",
        "                      size)\n",
        "\n",
        "print(f\"Writing {len(sample_images)} defective images to {OUTPUT_SLIDESHOW_PATH}...\")\n",
        "\n",
        "for image_path in tqdm(sample_images, desc=\"Creating defect video\"):\n",
        "    img = cv2.imread(image_path)\n",
        "    out.write(img)\n",
        "\n",
        "out.release()\n",
        "print(\"Defect slideshow video created successfully!\")"
      ],
      "metadata": {
        "id": "tzoelTESAvJb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d6b6d4a-caed-4909-ca48-a853b13ff4b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Part 1: Creating 'Slideshow' Video from DEFECTS ---\n",
            "Scanning 3948 labels in /content/fabric_dataset/labels/val...\n",
            "Found 974 defective images in the validation set.\n",
            "Writing 20 defective images to /content/demo_slideshow.mp4...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Creating defect video: 100%|██████████| 20/20 [00:00<00:00, 183.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defect slideshow video created successfully!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run Model & Predict"
      ],
      "metadata": {
        "id": "70yJOigZAxnh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Part 2: Running Inference ---\")\n",
        "\n",
        "# Load trained model\n",
        "print(f\"Loading model from {MODEL_PATH}...\")\n",
        "model = YOLO(MODEL_PATH)\n",
        "print(\"Model loaded successfully.\")\n",
        "\n",
        "# Run prediction\n",
        "print(f\"Running prediction on {OUTPUT_SLIDESHOW_PATH}...\")\n",
        "results = model.predict(\n",
        "    source=OUTPUT_SLIDESHOW_PATH,\n",
        "    save=True,\n",
        "    conf=0.25, # Confidence threshold\n",
        "    project=LOCAL_RESULTS_DIR,\n",
        "    name=\"demo_run\"\n",
        ")\n",
        "print(\"Prediction complete!\")\n",
        "\n",
        "actual_save_dir = results[0].save_dir\n",
        "\n",
        "predicted_video_local_path = os.path.join(actual_save_dir, \"demo_slideshow.avi\")\n",
        "\n",
        "final_drive_path = os.path.join(DRIVE_OUTPUT_DIR, FINAL_VIDEO_NAME)\n",
        "\n",
        "# 4. Copy the video to Google Drive\n",
        "print(f\"Located predicted video at: {predicted_video_local_path}\")\n",
        "print(f\"Copying to: {final_drive_path} ...\")\n",
        "\n",
        "!cp \"{predicted_video_local_path}\" \"{final_drive_path}\"\n",
        "\n",
        "print(\"\\n--- All Done! ---\")\n",
        "print(f\"Successfully saved your final video to Google Drive at:\")\n",
        "print(f\"{final_drive_path}\")"
      ],
      "metadata": {
        "id": "EpVZqpJ8Ay9G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d8fe021-b7f4-441e-eb3f-25dc58b314cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Part 2: Running Inference ---\n",
            "Loading model from /content/drive/My Drive/EEY9536 Data Science Project/Dataset/YOLO_Results/yolov8n_colab_run_b64/weights/best.pt...\n",
            "Model loaded successfully.\n",
            "Running prediction on /content/demo_slideshow.mp4...\n",
            "\n",
            "WARNING ⚠️ \n",
            "inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\n",
            "errors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n",
            "\n",
            "Example:\n",
            "    results = model(source=..., stream=True)  # generator of Results objects\n",
            "    for r in results:\n",
            "        boxes = r.boxes  # Boxes object for bbox outputs\n",
            "        masks = r.masks  # Masks object for segment masks outputs\n",
            "        probs = r.probs  # Class probabilities for classification outputs\n",
            "\n",
            "video 1/1 (frame 1/20) /content/demo_slideshow.mp4: 512x512 1 Defect, 8.0ms\n",
            "video 1/1 (frame 2/20) /content/demo_slideshow.mp4: 512x512 1 Defect, 6.9ms\n",
            "video 1/1 (frame 3/20) /content/demo_slideshow.mp4: 512x512 3 Defects, 5.7ms\n",
            "video 1/1 (frame 4/20) /content/demo_slideshow.mp4: 512x512 2 Defects, 6.2ms\n",
            "video 1/1 (frame 5/20) /content/demo_slideshow.mp4: 512x512 2 Defects, 6.4ms\n",
            "video 1/1 (frame 6/20) /content/demo_slideshow.mp4: 512x512 3 Defects, 6.1ms\n",
            "video 1/1 (frame 7/20) /content/demo_slideshow.mp4: 512x512 1 Defect, 6.1ms\n",
            "video 1/1 (frame 8/20) /content/demo_slideshow.mp4: 512x512 2 Defects, 6.4ms\n",
            "video 1/1 (frame 9/20) /content/demo_slideshow.mp4: 512x512 1 Defect, 6.3ms\n",
            "video 1/1 (frame 10/20) /content/demo_slideshow.mp4: 512x512 1 Defect, 6.0ms\n",
            "video 1/1 (frame 11/20) /content/demo_slideshow.mp4: 512x512 (no detections), 6.3ms\n",
            "video 1/1 (frame 12/20) /content/demo_slideshow.mp4: 512x512 1 Defect, 7.2ms\n",
            "video 1/1 (frame 13/20) /content/demo_slideshow.mp4: 512x512 2 Defects, 5.6ms\n",
            "video 1/1 (frame 14/20) /content/demo_slideshow.mp4: 512x512 1 Defect, 5.6ms\n",
            "video 1/1 (frame 15/20) /content/demo_slideshow.mp4: 512x512 1 Defect, 6.2ms\n",
            "video 1/1 (frame 16/20) /content/demo_slideshow.mp4: 512x512 3 Defects, 5.6ms\n",
            "video 1/1 (frame 17/20) /content/demo_slideshow.mp4: 512x512 1 Defect, 6.5ms\n",
            "video 1/1 (frame 18/20) /content/demo_slideshow.mp4: 512x512 1 Defect, 7.4ms\n",
            "video 1/1 (frame 19/20) /content/demo_slideshow.mp4: 512x512 1 Defect, 6.9ms\n",
            "video 1/1 (frame 20/20) /content/demo_slideshow.mp4: 512x512 1 Defect, 5.9ms\n",
            "Speed: 2.4ms preprocess, 6.4ms inference, 3.3ms postprocess per image at shape (1, 3, 512, 512)\n",
            "Results saved to \u001b[1m/content/prediction_results/demo_run\u001b[0m\n",
            "Prediction complete!\n",
            "Located predicted video at: /content/prediction_results/demo_run/demo_slideshow.avi\n",
            "Copying to: /content/drive/My Drive/EEY9536 Data Science Project/Dataset/Demo_Video/fabric_demo_with_boxes.mp4 ...\n",
            "\n",
            "--- All Done! ---\n",
            "Successfully saved your final video to Google Drive at:\n",
            "/content/drive/My Drive/EEY9536 Data Science Project/Dataset/Demo_Video/fabric_demo_with_boxes.mp4\n"
          ]
        }
      ]
    }
  ]
}